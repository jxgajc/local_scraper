# 全局优化升级方案 (全量重构版)

收到，我将对项目中**所有的爬虫**进行统一重构和升级。

## 1. 核心架构重构 (Core Architecture)

### 目标
建立标准化的开发范式，确保所有爬虫结构一致、易于维护。

### 实施细节
1.  **统一写入管道 (Universal Pipeline)**:
    *   **动作**: 重写 `pipelines.py`，创建一个智能的 `UniversalBatchWritePipeline`。
    *   **机制**: 移除所有 `*DrugPipeline` 子类。Pipeline 将通过 Item 的 `get_model_class()` 接口动态获取对应的数据模型，实现“一个管道处理所有数据”。
2.  **状态上报组件 (Status Mixin)**:
    *   **动作**: 新建 `hybrid_crawler/spiders/mixins.py`。
    *   **机制**: 封装 `SpiderStatusMixin`，提供标准化的 `report_start`, `report_item`, `report_error` 接口，彻底消除 Spider 中的重复样板代码。

## 2. 全量代码升级 (Full Scale Refactoring)

我将逐一处理以下模块：

### A. 模型层 (Models)
*   **涉及文件**: `fujian_drug.py`, `guangdong_drug.py`, `hainan_drug.py`, `hebei_drug.py`, `liaoning_drug.py`, `nhsa_drug.py`, `ningxia_drug.py`, `shandong_drug.py`, `tianjin_drug.py` 等。
*   **操作**: 为每个文件中的 Item 类添加 `get_model_class()` 方法，建立 Item 到 SQL Model 的映射关系。

### B. 爬虫层 (Spiders)
*   **涉及文件**: 上述省份对应的所有 Spider 文件。
*   **操作**:
    1.  **继承 Mixin**: 让所有 Spider 继承 `SpiderStatusMixin`。
    2.  **代码清理**: 使用 Mixin 方法替换冗长的字典构造代码。
    3.  **配置净化**: 移除硬编码的 `User-Agent` 和冗余的 Pipeline 配置 (统一走 Settings)。
    4.  **保持并发**: 保留各 Spider 原有的并发限制配置。

## 3. 中间件与配置 (Middlewares & Settings)

1.  **随机 User-Agent**:
    *   新增 `RandomUserAgentMiddleware`，配置 UA 池，实现全局自动切换。
2.  **全局配置更新**:
    *   在 `settings.py` 中注册新中间件和通用 Pipeline。

---

## 执行计划 (Roadmap)

1.  **基础设施建设**: 创建 `mixins.py`，重构 `pipelines.py` 和 `middlewares.py`。
2.  **批量更新模型**: 修改 `models/` 下的所有文件，添加映射方法。
3.  **批量重构爬虫**: 逐个重构 `spiders/` 下的所有爬虫文件 (Fujian, Guangdong, Hainan, Hebei, Liaoning, Nhsa, Ningxia, Shandong, Tianjin)。
4.  **配置生效**: 更新 `settings.py`。

这是一个涉及全项目的深度重构，确认开始执行？