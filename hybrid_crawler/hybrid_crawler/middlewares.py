import time
import random
import logging
from scrapy.downloadermiddlewares.retry import RetryMiddleware
from twisted.internet.error import (
    ConnectionRefusedError, DNSLookupError, TimeoutError, TCPTimedOutError
)
from .exceptions import CrawlerNetworkError, ElementNotFoundError, BrowserCrashError

logger = logging.getLogger(__name__)

class StrategyRoutingMiddleware:
    """
    ã€ç­–ç•¥è·¯ç”±ä¸­é—´ä»¶ã€‘
    ä½œç”¨ï¼šåœ¨è¯·æ±‚å‘å‡ºå‰ï¼Œæ ¹æ® Request çš„ meta æ ‡è®°ï¼Œå†³å®šæ˜¯å¦å¯ç”¨ Playwrightã€‚
    """
    def process_request(self, request, spider):
        request_type = request.meta.get('request_type', 'http')
        
        # å¦‚æœæ ‡è®°ä¸º playwrightï¼Œåˆ™æ¿€æ´» scrapy-playwright æ’ä»¶çš„å‚æ•°
        if request_type == 'playwright':
            request.meta['playwright'] = True
            request.meta['dont_merge_cookies'] = True # æµè§ˆå™¨è‡ªå·±ç®¡ç† Cookieï¼Œä¸ä½¿ç”¨ Scrapy çš„ CookieJar
        return None

class SmartRetryMiddleware(RetryMiddleware):
    """
    ã€æ™ºèƒ½é‡è¯•ä¸­é—´ä»¶ã€‘
    ä½œç”¨ï¼šæ›¿ä»£é»˜è®¤çš„ RetryMiddlewareï¼Œå®ç°åˆ†çº§é‡è¯•ç­–ç•¥ã€‚
    """
    NETWORK_ERRORS = (ConnectionRefusedError, DNSLookupError, TimeoutError, TCPTimedOutError, CrawlerNetworkError)
    LOGIC_ERRORS = (ElementNotFoundError, BrowserCrashError)

    def process_exception(self, request, exception, spider):
        retry_times = request.meta.get('retry_times', 0) + 1
        max_retries = self.max_retry_times

        if retry_times > max_retries:
            logger.error(f"âŒ æ”¾å¼ƒè¯·æ±‚ {request.url}: è¶…è¿‡æœ€å¤§é‡è¯•æ¬¡æ•°")
            return None

        # ç­–ç•¥ 1: ç½‘ç»œé”™è¯¯ -> æŒ‡æ•°é€€é¿ (Wait time = 2^(n-1))
        if isinstance(exception, self.NETWORK_ERRORS):
            delay = 2 ** (retry_times - 1)
            logger.warning(f"âš ï¸ ç½‘ç»œæ³¢åŠ¨ ({exception}), {delay}s åé‡è¯•: {request.url}")
            # æ”¹è‰¯ï¼šä¸è¦ä½¿ç”¨ time.sleep(delay)ï¼Œè¿™ä¼šé˜»å¡ reactorã€‚
            # æ­£ç¡®åšæ³•æ˜¯è®¾ç½® download_delayï¼Œè®© Scrapy çš„è°ƒåº¦å™¨å»ç­‰å¾…ã€‚
            new_request = self._retry(request, exception, spider)
            if new_request:
                new_request.meta['download_delay'] = delay
            return new_request
            
        # ç­–ç•¥ 2: é€»è¾‘/æ¸²æŸ“é”™è¯¯ -> å‡€å®¤é‡è¯• (Clean Slate)
        elif isinstance(exception, self.LOGIC_ERRORS):
            logger.warning(f"ğŸ”„ é€»è¾‘é”™è¯¯ ({exception}), è§¦å‘å‡€å®¤é‡è¯•: {request.url}")
            # å…³é”®ï¼šæ ‡è®° clean_slateï¼Œå‘Šè¯‰ Spider åœ¨ä¸‹æ¬¡è¯·æ±‚æ—¶é”€æ¯ Context
            request.meta['clean_slate'] = True 
            request.dont_filter = True
            return self._retry(request, exception, spider)

        return super().process_exception(request, exception, spider)