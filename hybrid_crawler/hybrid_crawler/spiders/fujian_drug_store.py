import scrapy
import json
import uuid
from ..models.fujian_drug import FujianDrugItem
from scrapy.http import JsonRequest
from ..utils.logger_utils import get_spider_logger

class FujianDrugSpider(scrapy.Spider):
    """
    ç¦å»ºçœåŒ»ç–—ä¿éšœå±€ - è¯å“æŒ‚ç½‘åŠé‡‡è´­åŒ»é™¢æŸ¥è¯¢
    Target: https://open.ybj.fujian.gov.cn:10013/tps-local/#/external/product-publicity
    """
    name = "fujian_drug_spider"
    
    # API Endpoints
    list_api_url = "https://open.ybj.fujian.gov.cn:10013/tps-local/web/tender/plus/item-cfg-info/list"
    hospital_api_url = "https://open.ybj.fujian.gov.cn:10013/tps-local/web/trans/api/open/v2/queryHospital"
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.spider_log = get_spider_logger(self.name)
        self.crawl_id = str(uuid.uuid4())
        self.spider_log.info(f"ğŸš€ çˆ¬è™«åˆå§‹åŒ–å®Œæˆï¼Œcrawl_id: {self.crawl_id}")

    custom_settings = {
        'CONCURRENT_REQUESTS': 5,
        'DOWNLOAD_DELAY': 3,
        'DEFAULT_REQUEST_HEADERS': {
            'Content-Type': 'application/json;charset=utf-8',
            'Accept': 'application/json, text/plain, */*',
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/18.5 Safari/605.1.15',
            'Origin': 'https://open.ybj.fujian.gov.cn:10013',
            'Referer': 'https://open.ybj.fujian.gov.cn:10013/tps-local/',
            # æ³¨æ„: è¿™é‡Œçš„Cookieå¯èƒ½æœ‰æ—¶æ•ˆæ€§ï¼Œå®é™…éƒ¨ç½²æ—¶å¯èƒ½éœ€è¦åŠ¨æ€è·å–æˆ–å®šæœŸæ›´æ–°
            # 'Cookie': 'A-pool-ui-5=16412.56937.19855.0000; _gscu_1203915485=64553900x15k8025',
            'prodType': '2',
            'Priority': 'u=3, i'
        },
        'ITEM_PIPELINES': {
            'hybrid_crawler.pipelines.DataCleaningPipeline': 300,        # æ¸…æ´—
            'hybrid_crawler.pipelines.CrawlStatusPipeline': 350, 
            'hybrid_crawler.pipelines.FujianDrugPipeline': 400,           # å…¥åº“
        }
    }

    def start_requests(self):
        """å¼€å§‹è¯·æ±‚è¯å“åˆ—è¡¨"""
        # åˆå§‹Payloadï¼Œsizeè®¾ä¸º100ä»¥æé«˜æ•ˆç‡
        payload = {
            "druglistName": "",
            "druglistCode": "",
            "drugName": "",
            "ruteName": "",
            "dosformName": "",
            "specName": "",
            "pac": "",
            "prodentpName": "",
            "current": 1,
            "size": 1000,
            "tenditmType": ""
        }
        
        self.spider_log.info(f"ğŸ“‹ å¼€å§‹é‡‡é›†è¯å“åˆ—è¡¨ï¼Œåˆå§‹payload: {json.dumps(payload)}")
        
        # # ä¸ŠæŠ¥å¼€å§‹é‡‡é›†çŠ¶æ€
        # yield {
        #     '_status_': True,
        #     'crawl_id': self.crawl_id,
        #     'stage': 'start_requests',
        #     'page_no': 1,
        #     'params': payload,
        #     'api_url': self.list_api_url,
        #     'success': True
        # }
        
        yield JsonRequest(
            url=self.list_api_url,
            method='POST',
            data=payload,
            callback=self.parse_drug_list,
            meta={'payload': payload, 'crawl_id': self.crawl_id},
            dont_filter=True
        )

    def parse_drug_list(self, response):
        """è§£æè¯å“åˆ—è¡¨"""
        page_crawl_id = str(uuid.uuid4())
        current_payload = response.meta['payload']
        
        try:
            res_json = json.loads(response.text)
            if res_json.get("code") != 0:
                error_msg = res_json.get('message', 'Unknown error')
                self.spider_log.error(f"âŒ è¯å“åˆ—è¡¨APIé”™è¯¯ (Page {current_payload['current']}): {error_msg}")
                
                # ä¸ŠæŠ¥å¤±è´¥çŠ¶æ€
                yield {
                    '_status_': True,
                    'crawl_id': page_crawl_id,
                    'stage': 'list_page',
                    'page_no': current_payload['current'],
                    'total_pages': 0,
                    'params': current_payload,
                    'api_url': self.list_api_url,
                    'success': False,
                    'error_message': error_msg,
                    'parent_crawl_id': self.crawl_id
                }
                return

            data_block = res_json.get("data", {})
            records = data_block.get("records", [])
            current_page = data_block.get("current", 1)
            total_pages = data_block.get("pages", 0)
            page_size = data_block.get("size", 1000)

            self.spider_log.info(f"ğŸ“„ è¯å“åˆ—è¡¨é¡µé¢ [{current_page}/{total_pages}] - å‘ç° {len(records)} æ¡è¯å“è®°å½•")
            
            # ä¸ŠæŠ¥é¡µé¢é‡‡é›†çŠ¶æ€
            yield {
                '_status_': True,
                'crawl_id': page_crawl_id,
                'stage': 'list_page',
                'page_no': current_page,
                'total_pages': total_pages,
                'page_size': page_size,
                'items_found': len(records),
                'params': current_payload,
                'api_url': self.list_api_url,
                'success': True,
                'parent_crawl_id': self.crawl_id
            }

            item_count = 0
            for record in records:
                # 1. æå–åŸºç¡€ä¿¡æ¯
                base_info = {
                    'ext_code': record.get('extCode'),
                    'drug_list_code': record.get('druglistCode'),
                    'drug_name': record.get('drugName'),
                    'drug_list_name': record.get('druglistName'),
                    'dosform': record.get('dosformName'),
                    'spec': record.get('specName'),
                    'pac': record.get('pac'),
                    'rute_name': record.get('ruteName'),
                    'prod_entp': record.get('prodentpName'),
                    'source_data': json.dumps(record, ensure_ascii=False)
                }

                # 2. æŸ¥è¯¢åŒ»é™¢é‡‡è´­ä¿¡æ¯
                # åªæœ‰ extCode å­˜åœ¨æ—¶æ‰èƒ½æŸ¥è¯¢
                ext_code = record.get('extCode')
                if ext_code:
                    hospital_payload = {
                        "area": "",
                        "hospitalName": "",
                        "pageNo": 1,
                        "pageSize": 100,
                        "productId": ext_code,
                        "tenditmType": ""
                    }
                    
                    yield JsonRequest(
                        url=self.hospital_api_url,
                        method='POST',
                        data=hospital_payload,
                        callback=self.parse_hospital,
                        meta={
                            'base_info': base_info,
                            'payload': hospital_payload,
                            'parent_crawl_id': page_crawl_id,
                            'drug_name': base_info['drug_name']
                        },
                        dont_filter=True
                    )
                    item_count += 1
                else:
                    # æ— IDï¼Œä»…ä¿å­˜åŸºç¡€ä¿¡æ¯
                    item = FujianDrugItem()
                    item.update(base_info)
                    item['has_hospital_record'] = False
                    item.generate_md5_id()
                    yield item
                    item_count += 1

            # æ›´æ–°é¡µé¢é‡‡é›†çŠ¶æ€ï¼Œè®°å½•æˆåŠŸå­˜å‚¨çš„æ¡æ•°
            yield {
                '_status_': True,
                'crawl_id': page_crawl_id,
                'stage': 'list_page',
                'page_no': current_page,
                'total_pages': total_pages,
                'page_size': page_size,
                'items_found': len(records),
                'items_stored': item_count,
                'params': current_payload,
                'api_url': self.list_api_url,
                'success': True,
                'parent_crawl_id': self.crawl_id
            }

            # 3. è¯å“åˆ—è¡¨ç¿»é¡µ
            if current_page < total_pages:
                self.spider_log.info(f"ğŸ”„ å‡†å¤‡é‡‡é›†ä¸‹ä¸€é¡µè¯å“åˆ—è¡¨ [{current_page + 1}/{total_pages}]")
                next_payload = current_payload.copy()
                next_payload['current'] = current_page + 1
                
                yield JsonRequest(
                    url=self.list_api_url,
                    method='POST',
                    data=next_payload,
                    callback=self.parse_drug_list,
                    meta={'payload': next_payload, 'crawl_id': self.crawl_id},
                    dont_filter=True
                )
            else:
                self.spider_log.info(f"âœ… è¯å“åˆ—è¡¨é‡‡é›†å®Œæˆï¼Œå…± {total_pages} é¡µ")

        except Exception as e:
            self.spider_log.error(f"âŒ è§£æè¯å“åˆ—è¡¨å¤±è´¥ (Page {current_payload.get('current', 1)}): {e}", exc_info=True)
            
            # ä¸ŠæŠ¥å¼‚å¸¸çŠ¶æ€
            yield {
                '_status_': True,
                'crawl_id': page_crawl_id,
                'stage': 'list_page',
                'page_no': current_payload.get('current', 1),
                'params': current_payload,
                'api_url': self.list_api_url,
                'success': False,
                'error_message': str(e),
                'parent_crawl_id': self.crawl_id
            }

    def parse_hospital(self, response):
        """è§£æåŒ»é™¢åˆ—è¡¨ï¼ˆåµŒå¥—JSONè§£æï¼‰"""
        base_info = response.meta['base_info']
        current_payload = response.meta['payload']
        parent_crawl_id = response.meta['parent_crawl_id']
        drug_name = response.meta['drug_name']
        hospital_crawl_id = str(uuid.uuid4())

        try:
            res_json = json.loads(response.text)
            
            # æ³¨æ„ï¼šdata å­—æ®µæ˜¯ä¸€ä¸ª JSON å­—ç¬¦ä¸²ï¼Œéœ€è¦äºŒæ¬¡è§£æ
            # ç¤ºä¾‹: "data": "{\"msg\":\"...\",\"total\":85,\"data\":[...]}"
            inner_data_str = res_json.get("data")
            
            if not inner_data_str or not isinstance(inner_data_str, str):
                # å¯èƒ½æ˜¯æ²¡æœ‰æ•°æ®æˆ–è€…æ ¼å¼ä¸å¯¹ï¼Œè§†ä¸ºæ— è®°å½•
                self.spider_log.warning(f"âš ï¸ è¯å“ [{drug_name}] åŒ»é™¢æ•°æ®æ ¼å¼å¼‚å¸¸ï¼Œè¿”å›ç©ºè®°å½•")
                
                # ä¸ŠæŠ¥åŒ»é™¢æŸ¥è¯¢çŠ¶æ€
                yield {
                    '_status_': True,
                    'crawl_id': hospital_crawl_id,
                    'stage': 'detail_page',
                    'page_no': current_payload['pageNo'],
                    'params': current_payload,
                    'api_url': self.hospital_api_url,
                    'success': True,
                    'items_found': 0,
                    'items_stored': 1,
                    'parent_crawl_id': parent_crawl_id,
                    'reference_id': base_info['ext_code']
                }
                
                # ç”Ÿæˆç©ºè®°å½•
                item = FujianDrugItem()
                item.update(base_info)
                item['has_hospital_record'] = False
                item.generate_md5_id()
                yield item
                return

            # äºŒæ¬¡è§£æ
            inner_json = json.loads(inner_data_str)
            hospitals = inner_json.get("data", [])
            total_records = int(inner_json.get("total", 0))
            current_page = int(inner_json.get("pageNo", 1))
            page_size = int(inner_json.get("pageSize", 100))
            
            total_pages = (total_records + page_size - 1) // page_size if total_records > 0 else 1

            self.spider_log.info(f"ğŸ¥ è¯å“ [{drug_name}] åŒ»é™¢åˆ—è¡¨ [{current_page}/{total_pages}] - å‘ç° {len(hospitals)} æ¡åŒ»é™¢è®°å½•")
            
            # ä¸ŠæŠ¥åŒ»é™¢æŸ¥è¯¢çŠ¶æ€
            yield {
                '_status_': True,
                'crawl_id': hospital_crawl_id,
                'stage': 'detail_page',
                'page_no': current_page,
                'total_pages': total_pages,
                'page_size': page_size,
                'items_found': len(hospitals),
                'params': current_payload,
                'api_url': self.hospital_api_url,
                'success': True,
                'parent_crawl_id': parent_crawl_id,
                'reference_id': base_info['ext_code']
            }

            item_count = 0
            if hospitals:
                for hosp in hospitals:
                    item = FujianDrugItem()
                    item.update(base_info)
                    
                    item['has_hospital_record'] = True
                    item['hospital_name'] = hosp.get('hospitalName')
                    item['medins_code'] = hosp.get('medinsCode')
                    item['area_name'] = hosp.get('areaName')
                    item['area_code'] = hosp.get('areaCode')
                    
                    # æ›´æ–° source_data åŒ…å«ä¸¤éƒ¨åˆ†
                    full_source = {
                        "drug_info": json.loads(base_info['source_data']),
                        "hospital_info": hosp
                    }
                    item['source_data'] = json.dumps(full_source, ensure_ascii=False)
                    
                    item.generate_md5_id()
                    yield item
                    item_count += 1
                
                # æ›´æ–°åŒ»é™¢æŸ¥è¯¢çŠ¶æ€ï¼Œè®°å½•æˆåŠŸå­˜å‚¨çš„æ¡æ•°
                yield {
                    '_status_': True,
                    'crawl_id': hospital_crawl_id,
                    'stage': 'detail_page',
                    'page_no': current_page,
                    'total_pages': total_pages,
                    'items_found': len(hospitals),
                    'items_stored': item_count,
                    'params': current_payload,
                    'api_url': self.hospital_api_url,
                    'success': True,
                    'parent_crawl_id': parent_crawl_id,
                    'reference_id': base_info['ext_code']
                }
                
                # 4. åŒ»é™¢åˆ—è¡¨ç¿»é¡µ
                if current_page < total_pages:
                    self.spider_log.info(f"ğŸ”„ å‡†å¤‡é‡‡é›†è¯å“ [{drug_name}] ä¸‹ä¸€é¡µåŒ»é™¢åˆ—è¡¨ [{current_page + 1}/{total_pages}]")
                    next_payload = current_payload.copy()
                    next_payload['pageNo'] = current_page + 1
                    
                    yield JsonRequest(
                        url=self.hospital_api_url,
                        method='POST',
                        data=next_payload,
                        callback=self.parse_hospital,
                        meta={
                            'base_info': base_info,
                            'payload': next_payload,
                            'parent_crawl_id': parent_crawl_id,
                            'drug_name': drug_name
                        },
                        dont_filter=True
                    )
            else:
                # è§£ææˆåŠŸä½†åˆ—è¡¨ä¸ºç©º
                if current_page == 1:
                    self.spider_log.info(f"ğŸ“‹ è¯å“ [{drug_name}] æ²¡æœ‰åŒ»é™¢é‡‡è´­è®°å½•")
                    
                    # ä¸ŠæŠ¥åŒ»é™¢æŸ¥è¯¢çŠ¶æ€
                    yield {
                        '_status_': True,
                        'crawl_id': hospital_crawl_id,
                        'stage': 'detail_page',
                        'page_no': current_page,
                        'total_pages': total_pages,
                        'items_found': 0,
                        'items_stored': 1,
                        'params': current_payload,
                        'api_url': self.hospital_api_url,
                        'success': True,
                        'parent_crawl_id': parent_crawl_id,
                        'reference_id': base_info['ext_code']
                    }
                    
                    item = FujianDrugItem()
                    item.update(base_info)
                    item['has_hospital_record'] = False
                    item.generate_md5_id()
                    yield item
                    item_count += 1

        except Exception as e:
            self.spider_log.error(f"âŒ è¯å“ [{drug_name}] åŒ»é™¢æŸ¥è¯¢å¤±è´¥: {e}", exc_info=True)
            
            # ä¸ŠæŠ¥å¼‚å¸¸çŠ¶æ€
            yield {
                '_status_': True,
                'crawl_id': hospital_crawl_id,
                'stage': 'detail_page',
                'page_no': current_payload['pageNo'],
                'params': current_payload,
                'api_url': self.hospital_api_url,
                'success': False,
                'error_message': str(e),
                'parent_crawl_id': parent_crawl_id,
                'reference_id': base_info['ext_code']
            }