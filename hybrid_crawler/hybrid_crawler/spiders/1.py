import scrapy
import json
import time
from datetime import datetime
from .base_spiders import BaseRequestSpider
from ..models.nhsa_drug import NhsaDrugItem

class NhsaDrugSpiderSpider(BaseRequestSpider):
    """
    国家医保药品目录采集 (Pro)
    Generated by Spider Studio Pro
    """
    name = "nhsa_drug_spider"
    api_url = "https://code.nhsa.gov.cn/yp/getPublishGoodsDataInfo.html"

    custom_settings = {
        'CONCURRENT_REQUESTS': 1,
        'DOWNLOAD_DELAY': 15,
        'DEFAULT_REQUEST_HEADERS': {
            'Referer': 'https://code.nhsa.gov.cn/yp/toPublishGoodsData.html',
            'Origin': 'https://code.nhsa.gov.cn',
        },
        'ITEM_PIPELINES': {
            'hybrid_crawler.pipelines.DataCleaningPipeline': 300,
            'hybrid_crawler.pipelines.NhsaDrugPipeline': 400,
        }
    }

    def start_requests(self):
        """构造初始请求"""
        # 构造 Payload
        payload = {
            'batchNumber': '20251201',
            'rows': '1000',
            'page': '1',
            'nd': str(int(time.time() * 1000))
        }
        
        yield scrapy.FormRequest(
            url=self.api_url,
            method='POST',
            formdata=payload,
            callback=self.parse_logic,
            meta={'payload': payload}, # 传递状态用于翻页
            dont_filter=True
        )

    def parse_logic(self, response):
        try:
            res_json = json.loads(response.text)
            
            # 1. 提取列表数据
            # 路径: rows
            records = res_json.get("rows", [])
            
            for row in records:
                item = NhsaDrugItem()
                
                # --- 字段映射 ---
                item['goodsname'] = row.get('goodsname', '')
                item['approvalcode'] = row.get('approvalcode', '')
                item['price'] = row.get('price', '')
                
                item['url'] = response.url # 或构造详情页URL
                # item.generate_md5_id()
                yield item

            # 2. 翻页逻辑
            # 注意: payload 需从 response.meta 中获取以保持连贯性
            payload = response.meta.get('payload', {})
# --- 递归翻页 ---
            # 简单参数递增... (略)

        except Exception as e:
            self.logger.error(f"解析失败: {e} | Response: {response.text[:200]}")
