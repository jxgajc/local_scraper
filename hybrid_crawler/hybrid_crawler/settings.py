import os

BOT_NAME = 'hybrid_crawler'
SPIDER_MODULES = ['hybrid_crawler.spiders']
NEWSPIDER_MODULE = 'hybrid_crawler.spiders'

# =============================================================================
# æ ¸å¿ƒå¹¶å‘é…ç½®
# =============================================================================
CONCURRENT_REQUESTS = 32
DOWNLOAD_DELAY = 0

# =============================================================================
# ä¸­é—´ä»¶ç®¡é“é…ç½®
# =============================================================================
DOWNLOADER_MIDDLEWARES = {
    'hybrid_crawler.middlewares.StrategyRoutingMiddleware': 100, # è·¯ç”±ç­–ç•¥
    'hybrid_crawler.middlewares.SmartRetryMiddleware': 550,      # æ™ºèƒ½é‡è¯•
    'scrapy.downloadermiddlewares.retry.RetryMiddleware': None,  # ç¦ç”¨é»˜è®¤é‡è¯•
}

ITEM_PIPELINES = {
    'hybrid_crawler.pipelines.DataCleaningPipeline': 300,        # æ¸…æ´—
    'hybrid_crawler.pipelines.CrawlStatusPipeline': 350,         # é‡‡é›†çŠ¶æ€è®°å½•
    'hybrid_crawler.pipelines.AsyncBatchWritePipeline': 400,     # å…¥åº“
}

# =============================================================================
# å¼‚æ­¥å†™å…¥ç¼“å†²é…ç½®
# =============================================================================
BUFFER_THRESHOLD = 500  # ç§¯æ”’ 50 æ¡å†™å…¥ä¸€æ¬¡
BUFFER_TIMEOUT_SEC = 1.5 # æˆ–æœ€é•¿ç­‰å¾… 1.5 ç§’å†™å…¥ä¸€æ¬¡

# =============================================================================
# Playwright ä¸“ç”¨é…ç½®
# =============================================================================
# try:
#     from scrapy_playwright.handler import ScrapyPlaywrightDownloadHandler
#     DOWNLOAD_HANDLERS = {
#         "http": "scrapy_playwright.handler.ScrapyPlaywrightDownloadHandler",
#         "https": "scrapy_playwright.handler.ScrapyPlaywrightDownloadHandler",
#     }
#     # å¿…é¡»ä½¿ç”¨ Asyncio ååº”å †
#     TWISTED_REACTOR = "twisted.internet.asyncioreactor.AsyncioSelectorReactor"
#     # ğŸ’¡ Debug: å°† headless æ”¹ä¸º False å¯çœ‹åˆ°æµè§ˆå™¨
#     PLAYWRIGHT_LAUNCH_OPTIONS = {
#         'headless': True,
#         'args': ['--no-sandbox', '--disable-dev-shm-usage', '--disable-gpu'],
#         'timeout': 30000, # å¯åŠ¨è¶…æ—¶æ—¶é—´
#     }
# except ImportError:
#     # å¦‚æœæ— æ³•å¯¼å…¥ scrapy_playwrightï¼Œä½¿ç”¨é»˜è®¤çš„ä¸‹è½½å¤„ç†å™¨
#     DOWNLOAD_HANDLERS = {}
#     # ä¸éœ€è¦è®¾ç½® Asyncio ååº”å †
#     pass

LOG_LEVEL = 'INFO'
# æ—¥å¿—é…ç½®
LOG_ENABLED = True
LOG_ENCODING = 'utf-8'
LOG_FORMAT = '%(asctime)s - %(name)s - %(levelname)s - %(filename)s:%(lineno)d - %(message)s'
LOG_DATEFORMAT = '%Y-%m-%d %H:%M:%S'

# æ—¥å¿—ä¿å­˜è·¯å¾„
script_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
log_dir = os.path.join(script_dir, 'log')
os.makedirs(log_dir, exist_ok=True)

# ç¦ç”¨ Scrapy é»˜è®¤çš„æ–‡ä»¶æ—¥å¿—ï¼Œä½¿ç”¨æˆ‘ä»¬çš„è‡ªå®šä¹‰æ—¥å¿—ç®¡ç†å™¨
LOG_FILE = None

# æ—¥å¿—å¤„ç†å™¨é…ç½®
LOG_STDOUT = True

# ä¸ºä¸åŒæ¨¡å—è®¾ç½®æ—¥å¿—çº§åˆ«
LOG_LEVELS = {
    'scrapy': 'WARNING',
    'twisted': 'WARNING',
    'hybrid_crawler': 'INFO',
}

