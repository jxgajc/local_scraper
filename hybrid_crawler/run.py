import os
import sys

from scrapy.crawler import CrawlerProcess
from scrapy.utils.project import get_project_settings

# è®¾ç½® Scrapy é…ç½®æ–‡ä»¶è·¯å¾„
os.environ['SCRAPY_SETTINGS_MODULE'] = 'hybrid_crawler.settings'

# å¯¼å…¥çˆ¬è™« (éœ€ç¡®ä¿å·²å®‰è£… Twisted Asyncio Reactor)
from hybrid_crawler.spiders.example import HackerNewsSpider, DynamicQuotesSpider
from hybrid_crawler.spiders.hainan_drug_store import HainanDrugStoreSpider
from hybrid_crawler.spiders.nhsa_drug_spider import NhsaDrugSpider
# çˆ¬è™«æ˜ å°„è¡¨
SPIDER_MAP = {
    # 'hn_simple': HackerNewsSpider,
    # 'quotes_dynamic': DynamicQuotesSpider,
    # 'hainan_drug_store': HainanDrugStoreSpider,
    # 'hainan_drug_store': HainanDrugStoreSpider,
    'nhsa_drug_spider': NhsaDrugSpider,
}

def run():
    print(">>> æ­£åœ¨å¯åŠ¨æ··åˆçˆ¬è™«ç³»ç»Ÿ...")
    
    # ç®€å•çš„å‚æ•°è§£æï¼Œç”¨äºå¼€å¯ Debug æ¨¡å¼å’ŒæŒ‡å®šçˆ¬è™«
    is_debug = 'debug' in sys.argv
    
    # è·å–è¦è¿è¡Œçš„çˆ¬è™«åç§°
    spider_name = None
    for arg in sys.argv[1:]:
        if arg != 'debug' and arg in SPIDER_MAP:
            spider_name = arg
            break
    
    settings = get_project_settings()
    
    if is_debug:
        print(">>> ğŸ Debug æ¨¡å¼å·²å¼€å¯: æ—¥å¿—çº§åˆ« DEBUG")
        settings.set('LOG_LEVEL', 'DEBUG')
    
    process = CrawlerProcess(settings)
    
    if spider_name:
        # è¿è¡ŒæŒ‡å®šçš„çˆ¬è™«
        print(f">>> æ­£åœ¨è¿è¡Œçˆ¬è™«: {spider_name}")
        process.crawl(SPIDER_MAP[spider_name])
    else:
        # é»˜è®¤è¿è¡Œæ‰€æœ‰çˆ¬è™«
        print(">>> æ­£åœ¨è¿è¡Œæ‰€æœ‰çˆ¬è™«")
        for spider in SPIDER_MAP.values():
            process.crawl(spider)
    
    process.start()

if __name__ == '__main__':
    run()